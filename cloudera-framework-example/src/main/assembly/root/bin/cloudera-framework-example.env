###############################################################################
# 
# Environment
#
###############################################################################

#
# Cluster network
#

# Can (should) be generated by reflecting on Cloudera Manager, eg https://raw.githubusercontent.com/ggear/cloudera-director-wrapper/master/src/main/assembly/layout/bin/cloudera-director-network
if [ -f $HADOOP_CONF_DIR/cluster.properties ]; then
	source $HADOOP_CONF_DIR/cluster.properties
else
	export CLUSTER_NODE_USER="root"
	export CLUSTER_NODE_KEY="/root/.ssh/launchpad"
	export MANAGER_SERVER_HOST="ip-10-0-0-87.eu-west-1.compute.internal."
	export MANAGER_SERVER_PORT="7180"
	export MANAGER_SERVER_HOSTS="ip-10-0-0-87.eu-west-1.compute.internal."
	export MANAGER_SERVER_PORTS="7180"
	export MANAGER_SERVER_HOSTS_AND_PORTS="ip-10-0-0-87.eu-west-1.compute.internal.:7180"
	export MANAGER_NAVIGATORMETASERVER_HOST="ip-10-0-0-87.eu-west-1.compute.internal"
	export MANAGER_NAVIGATORMETASERVER_PORT="7187"
	export MANAGER_NAVIGATORMETASERVER_HOSTS="ip-10-0-0-87.eu-west-1.compute.internal"
	export MANAGER_NAVIGATORMETASERVER_PORTS="7187"
	export MANAGER_NAVIGATORMETASERVER_HOSTS_AND_PORTS="ip-10-0-0-87.eu-west-1.compute.internal:7187"
	export HDFS_NAMENODE_HOST="ip-10-0-0-110.eu-west-1.compute.internal"
	export HDFS_NAMENODE_PORT="8020"
	export HDFS_NAMENODE_HOSTS="ip-10-0-0-110.eu-west-1.compute.internal"
	export HDFS_NAMENODE_PORTS="8020"
	export HDFS_NAMENODE_HOSTS_AND_PORTS="ip-10-0-0-110.eu-west-1.compute.internal:8020"
	export HIVE_HIVESERVER2_HOST="ip-10-0-0-110.eu-west-1.compute.internal"
	export HIVE_HIVESERVER2_PORT="10000"
	export HIVE_HIVESERVER2_HOSTS="ip-10-0-0-110.eu-west-1.compute.internal"
	export HIVE_HIVESERVER2_PORTS="10000"
	export HIVE_HIVESERVER2_HOSTS_AND_PORTS="ip-10-0-0-110.eu-west-1.compute.internal:10000"
	export KAFKA_KAFKA_BROKER_HOST="ip-10-0-0-72.eu-west-1.compute.internal"
	export KAFKA_KAFKA_BROKER_PORT="9092"
	export KAFKA_KAFKA_BROKER_HOSTS="ip-10-0-0-72.eu-west-1.compute.internal,ip-10-0-0-73.eu-west-1.compute.internal,ip-10-0-0-71.eu-west-1.compute.internal"
	export KAFKA_KAFKA_BROKER_PORTS="9092,9092,9092"
	export KAFKA_KAFKA_BROKER_HOSTS_AND_PORTS="ip-10-0-0-72.eu-west-1.compute.internal:9092,ip-10-0-0-73.eu-west-1.compute.internal:9092,ip-10-0-0-71.eu-west-1.compute.internal:9092"
	export ZOOKEEPER_SERVER_HOST="ip-10-0-0-73.eu-west-1.compute.internal"
	export ZOOKEEPER_SERVER_PORT="2181"
	export ZOOKEEPER_SERVER_HOSTS="ip-10-0-0-73.eu-west-1.compute.internal,ip-10-0-0-72.eu-west-1.compute.internal,ip-10-0-0-71.eu-west-1.compute.internal"
	export ZOOKEEPER_SERVER_PORTS="2181,2181,2181"
	export ZOOKEEPER_SERVER_HOSTS_AND_PORTS="ip-10-0-0-73.eu-west-1.compute.internal:2181,ip-10-0-0-72.eu-west-1.compute.internal:2181,ip-10-0-0-71.eu-west-1.compute.internal:2181"
	export FLUME_AGENT_HOST="ip-10-0-0-72.eu-west-1.compute.internal"
	export FLUME_AGENT_PORT="41414"
	export FLUME_AGENT_HOSTS="ip-10-0-0-72.eu-west-1.compute.internal,ip-10-0-0-71.eu-west-1.compute.internal,ip-10-0-0-73.eu-west-1.compute.internal"
	export FLUME_AGENT_PORTS="41414,41414,41414"
	export FLUME_AGENT_HOSTS_AND_PORTS="ip-10-0-0-72.eu-west-1.compute.internal:41414,ip-10-0-0-71.eu-west-1.compute.internal:41414,ip-10-0-0-73.eu-west-1.compute.internal:41414"
	export IMPALA_IMPALAD_HOST="ip-10-0-0-72.eu-west-1.compute.internal"
	export IMPALA_IMPALAD_PORT="21000"
	export IMPALA_IMPALAD_HOSTS="ip-10-0-0-72.eu-west-1.compute.internal,ip-10-0-0-73.eu-west-1.compute.internal,ip-10-0-0-71.eu-west-1.compute.internal"
	export IMPALA_IMPALAD_PORTS="21000,21000,21000"
	export IMPALA_IMPALAD_HOSTS_AND_PORTS="ip-10-0-0-72.eu-west-1.compute.internal:21000,ip-10-0-0-73.eu-west-1.compute.internal:21000,ip-10-0-0-71.eu-west-1.compute.internal:21000"
	export HUE_HUE_SERVER_HOST="ip-10-0-0-110.eu-west-1.compute.internal"
	export HUE_HUE_SERVER_PORT="8888"
	export HUE_HUE_SERVER_HOSTS="ip-10-0-0-110.eu-west-1.compute.internal"
	export HUE_HUE_SERVER_PORTS="8888"
	export HUE_HUE_SERVER_HOSTS_AND_PORTS="ip-10-0-0-110.eu-west-1.compute.internal:8888"
fi

#
# Root
#

export ROOT_DIR=$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )/..

#
# Parcel
#

if [ -f $ROOT_DIR/lib/parcel/parcel.env ]; then
  source $ROOT_DIR/lib/parcel/parcel.env
fi

#
# Application
#

export USER_SERVER=server1
export USER_ADMIN=hive
export USER_APP=$PARCEL_NAMESPACE
export DATABASE_APP=$PARCEL_NAMESPACE
export ROOT_HDFS=hdfs://$HDFS_NAMENODE_HOST
export ROOT_DIR_HDFS=/tmp/$PARCEL_LABEL/$PARCEL_VERSION
export ROOT_DIR_HDFS_RAW=$ROOT_DIR_HDFS/raw
export ROOT_DIR_HDFS_RAW_CANONICAL=$ROOT_DIR_HDFS_RAW/canonical
export ROOT_DIR_HDFS_STAGED=$ROOT_DIR_HDFS/staged
export ROOT_DIR_HDFS_STAGED_CANONICAL=$ROOT_DIR_HDFS_STAGED/canonical
export ROOT_DIR_HDFS_STAGED_MALFORMED=$ROOT_DIR_HDFS_STAGED/malformed
export ROOT_DIR_HDFS_PARTITIONED=$ROOT_DIR_HDFS/partitioned
export ROOT_DIR_HDFS_PARTITIONED_CANONICAL=$ROOT_DIR_HDFS_PARTITIONED/canonical
export ROOT_DIR_HDFS_PARTITIONED_DUPLICATE=$ROOT_DIR_HDFS_PARTITIONED/duplicate
export ROOT_DIR_HDFS_PARTITIONED_MALFORMED=$ROOT_DIR_HDFS_PARTITIONED/malformed
export ROOT_DIR_HDFS_PROCESSED=$ROOT_DIR_HDFS/processed
export ROOT_DIR_HDFS_PROCESSED_CANONICAL=$ROOT_DIR_HDFS_PROCESSED/canonical
export ROOT_DIR_HDFS_PROCESSED_REWRITTEN=$ROOT_DIR_HDFS_PROCESSED/rewritten
export ROOT_DIR_HDFS_PROCESSED_DUPLICATE=$ROOT_DIR_HDFS_PROCESSED/duplicate
export ROOT_DIR_HDFS_PROCESSED_MALFORMED=$ROOT_DIR_HDFS_PROCESSED/malformed

#
# Classpath
#

export LIBJARS="$(echo -n $(ls -m $ROOT_DIR/lib/jar/dep/*.jar)|sed 's/, /,/g')"
export HADOOP_CLASSPATH="$(echo -n $(ls -m $ROOT_DIR/lib/jar/dep/*.jar)|sed 's/, /:/g')"

###############################################################################
