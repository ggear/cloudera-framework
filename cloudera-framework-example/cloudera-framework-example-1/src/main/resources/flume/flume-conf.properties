###############################################################################
#
# Flume / Kafka ingest pipeline, offering 3 broadcast channels that can be 
# tapped with differing qualities of service:
#
#   1. single/non-durable, optimised for lowest latency delivery of single events,
#      add memory channel to mydataset.sources.source_single.channels
#   2. single/durable, optimised for low latency delivery of single events with
#      durable operation, add kafka channel with topic mydataset_single to
#      mydataset.sources.source_single.channels
#   3. batch/durable, optimised for greatest throughput of batch events with
#      durable operation, add kafka channel with topic mydataset_batch to 
#      mydataset.sources.source_batch.channels
#
###############################################################################
#
$FLUME_AGENT_NAME.sources=source_single source_batch
$FLUME_AGENT_NAME.channels=channel_single_durable channel_batch_durable
$FLUME_AGENT_NAME.sinks=sink_batch_hdfs
#
$FLUME_AGENT_NAME.sources.source_single.type=com.cloudera.framework.example.one.stream.Stream
$FLUME_AGENT_NAME.sources.source_single.recordType=$RECORD_FORMAT
$FLUME_AGENT_NAME.sources.source_single.pollMs=1000
$FLUME_AGENT_NAME.sources.source_single.pollTicks=1
$FLUME_AGENT_NAME.sources.source_single.batchSize=1
$FLUME_AGENT_NAME.sources.source_single.recordNumber=2000
$FLUME_AGENT_NAME.sources.source_single.interceptors=interceptor_stream
$FLUME_AGENT_NAME.sources.source_single.interceptors.interceptor_stream.type=com.cloudera.framework.example.one.stream.Stream$Interceptor$Builder
$FLUME_AGENT_NAME.sources.source_single.selector.type=replicating
$FLUME_AGENT_NAME.sources.source_single.channels=channel_single_durable
#
$FLUME_AGENT_NAME.channels.channel_single_durable.type=org.apache.flume.channel.kafka.KafkaChannel
$FLUME_AGENT_NAME.channels.channel_single_durable.kafka.bootstrap.servers=$KAFKA_KAFKA_BROKER_HOSTS_AND_PORTS
$FLUME_AGENT_NAME.channels.channel_single_durable.kafka.consumer.group.id=$TOPIC_APP_mydataset_single
$FLUME_AGENT_NAME.channels.channel_single_durable.kafka.topic=$TOPIC_APP_mydataset_single
$FLUME_AGENT_NAME.channels.channel_single_durable.kafka.consumer.auto.offset.reset=latest
$FLUME_AGENT_NAME.channels.channel_single_durable.capacity=10000
$FLUME_AGENT_NAME.channels.channel_single_durable.transactionCapacity=1000
#
$FLUME_AGENT_NAME.sources.source_batch.type=org.apache.flume.source.kafka.KafkaSource
$FLUME_AGENT_NAME.sources.source_batch.kafka.bootstrap.servers=$KAFKA_KAFKA_BROKER_HOSTS_AND_PORTS
$FLUME_AGENT_NAME.sources.source_batch.kafka.consumer.group.id=$TOPIC_APP_mydataset_single
$FLUME_AGENT_NAME.sources.source_batch.kafka.topics=$TOPIC_APP_mydataset_single
$FLUME_AGENT_NAME.sources.source_batch.kafka.consumer.auto.offset.reset=latest
$FLUME_AGENT_NAME.sources.source_batch.batchSize=20
$FLUME_AGENT_NAME.sources.source_batch.batchDurationMillis=700000
$FLUME_AGENT_NAME.sources.source_batch.interceptors=interceptor_unwrap interceptor_stream
$FLUME_AGENT_NAME.sources.source_batch.interceptors.interceptor_unwrap.type=com.cloudera.framework.common.flume.FlumeEventUnwrapInterceptor$Builder
$FLUME_AGENT_NAME.sources.source_batch.interceptors.interceptor_stream.type=com.cloudera.framework.example.one.stream.Stream$Interceptor$Builder
$FLUME_AGENT_NAME.sources.source_batch.selector.type=replicating
$FLUME_AGENT_NAME.sources.source_batch.channels=channel_batch_durable
#
$FLUME_AGENT_NAME.channels.channel_batch_durable.type=org.apache.flume.channel.kafka.KafkaChannel
$FLUME_AGENT_NAME.channels.channel_batch_durable.kafka.bootstrap.servers=$KAFKA_KAFKA_BROKER_HOSTS_AND_PORTS
$FLUME_AGENT_NAME.channels.channel_batch_durable.kafka.consumer.group.id=$TOPIC_APP_mydataset_batch
$FLUME_AGENT_NAME.channels.channel_batch_durable.kafka.topic=$TOPIC_APP_mydataset_batch
$FLUME_AGENT_NAME.channels.channel_batch_durable.kafka.consumer.auto.offset.reset=latest
$FLUME_AGENT_NAME.channels.channel_batch_durable.capacity=10000
$FLUME_AGENT_NAME.channels.channel_batch_durable.transactionCapacity=1000
#
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.type=hdfs
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.hdfs.path=$ROOT_HDFS$ROOT_DIR_HDFS/staged/canonical/sequence/%{bt}/none/ingest_batch_id=%{bid}/ingest_batch_start=%{btss}/ingest_batch_finish=%{btsf}
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.hdfs.filePrefix=mydataset
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.hdfs.fileSuffix=.$RECORD_FORMAT.seq
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.hdfs.inUsePrefix=_
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.hdfs.rollCount=0
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.hdfs.rollInterval=0
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.hdfs.rollSize=0
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.hdfs.idleTimeout=1
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.hdfs.batchSize=20
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.hdfs.writeFormat=com.cloudera.framework.example.one.stream.Stream$Serializer$Builder
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.hdfs.fileType=SequenceFile
$FLUME_AGENT_NAME.sinks.sink_batch_hdfs.channel=channel_batch_durable
#